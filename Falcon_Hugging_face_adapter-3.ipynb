{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP2+NfF8x4rK/2Z6vP0p6Q+",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "e_z0qZ0aX-m-"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Falcon_Hugging_face_adapter.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/15cOnEWMSFnfpXdAg5Sc9yaLTMB7Nu_ID\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J1xI7I7aX-m-"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes datasets accelerate loralib\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K3sK3K3kX-m-"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q einops"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L5tL5L5lX-m-"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M7uM7M7mX-m-"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "#dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] == 8 else torch.float16\n",
    "\n",
    "model_id = \"falcon-7B-instruct-600steps\"\n",
    "#model_id = \"falcon-40B-instruct-600steps\"\n",
    "config = PeftConfig.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N9vN9N9nX-m-"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        config.base_model_name
